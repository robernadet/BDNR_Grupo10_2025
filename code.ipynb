{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2xuAXHPI7FqM",
        "outputId": "cb3968a7-74ec-487e-a4db-fc9eb1f42f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: py2neo in ./.venv/lib/python3.13/site-packages (2021.2.4)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from py2neo) (2025.4.26)\n",
            "Requirement already satisfied: interchange~=2021.0.4 in ./.venv/lib/python3.13/site-packages (from py2neo) (2021.0.4)\n",
            "Requirement already satisfied: monotonic in ./.venv/lib/python3.13/site-packages (from py2neo) (1.6)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from py2neo) (25.0)\n",
            "Requirement already satisfied: pansi>=2020.7.3 in ./.venv/lib/python3.13/site-packages (from py2neo) (2024.11.0)\n",
            "Requirement already satisfied: pygments>=2.0.0 in ./.venv/lib/python3.13/site-packages (from py2neo) (2.19.1)\n",
            "Requirement already satisfied: six>=1.15.0 in ./.venv/lib/python3.13/site-packages (from py2neo) (1.17.0)\n",
            "Requirement already satisfied: urllib3 in ./.venv/lib/python3.13/site-packages (from py2neo) (2.4.0)\n",
            "Requirement already satisfied: pytz in ./.venv/lib/python3.13/site-packages (from interchange~=2021.0.4->py2neo) (2025.2)\n",
            "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from pansi>=2020.7.3->py2neo) (11.2.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: ipykernel in ./.venv/lib/python3.13/site-packages (6.29.5)\n",
            "Requirement already satisfied: appnope in ./.venv/lib/python3.13/site-packages (from ipykernel) (0.1.4)\n",
            "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.13/site-packages (from ipykernel) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.13/site-packages (from ipykernel) (1.8.14)\n",
            "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.13/site-packages (from ipykernel) (9.3.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.13/site-packages (from ipykernel) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.13/site-packages (from ipykernel) (5.8.1)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.13/site-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.13/site-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from ipykernel) (25.0)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.13/site-packages (from ipykernel) (7.0.0)\n",
            "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.13/site-packages (from ipykernel) (26.4.0)\n",
            "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.13/site-packages (from ipykernel) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.13/site-packages (from ipykernel) (5.14.3)\n",
            "Requirement already satisfied: decorator in ./.venv/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
            "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
            "Requirement already satisfied: stack_data in ./.venv/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.13/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.8)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.13/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.13/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.13/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in ./.venv/lib/python3.13/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: neo4jupyter in ./.venv/lib/python3.13/site-packages (0.2.0)\n",
            "Requirement already satisfied: IPython>=4.0.0 in ./.venv/lib/python3.13/site-packages (from neo4jupyter) (9.3.0)\n",
            "Requirement already satisfied: ipython-cypher>=0.2.4 in ./.venv/lib/python3.13/site-packages (from neo4jupyter) (0.2.6)\n",
            "Requirement already satisfied: py2neo in ./.venv/lib/python3.13/site-packages (from neo4jupyter) (2021.2.4)\n",
            "Requirement already satisfied: decorator in ./.venv/lib/python3.13/site-packages (from IPython>=4.0.0->neo4jupyter) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.13/site-packages (from IPython>=4.0.0->neo4jupyter) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.13/site-packages (from IPython>=4.0.0->neo4jupyter) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.13/site-packages (from IPython>=4.0.0->neo4jupyter) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.13/site-packages (from IPython>=4.0.0->neo4jupyter) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.13/site-packages (from IPython>=4.0.0->neo4jupyter) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.13/site-packages (from IPython>=4.0.0->neo4jupyter) (2.19.1)\n",
            "Requirement already satisfied: stack_data in ./.venv/lib/python3.13/site-packages (from IPython>=4.0.0->neo4jupyter) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in ./.venv/lib/python3.13/site-packages (from IPython>=4.0.0->neo4jupyter) (5.14.3)\n",
            "Requirement already satisfied: neo4jrestclient>=2.1.0 in ./.venv/lib/python3.13/site-packages (from ipython-cypher>=0.2.4->neo4jupyter) (2.1.1)\n",
            "Requirement already satisfied: prettytable in ./.venv/lib/python3.13/site-packages (from ipython-cypher>=0.2.4->neo4jupyter) (3.16.0)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from py2neo->neo4jupyter) (2025.4.26)\n",
            "Requirement already satisfied: interchange~=2021.0.4 in ./.venv/lib/python3.13/site-packages (from py2neo->neo4jupyter) (2021.0.4)\n",
            "Requirement already satisfied: monotonic in ./.venv/lib/python3.13/site-packages (from py2neo->neo4jupyter) (1.6)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from py2neo->neo4jupyter) (25.0)\n",
            "Requirement already satisfied: pansi>=2020.7.3 in ./.venv/lib/python3.13/site-packages (from py2neo->neo4jupyter) (2024.11.0)\n",
            "Requirement already satisfied: six>=1.15.0 in ./.venv/lib/python3.13/site-packages (from py2neo->neo4jupyter) (1.17.0)\n",
            "Requirement already satisfied: urllib3 in ./.venv/lib/python3.13/site-packages (from py2neo->neo4jupyter) (2.4.0)\n",
            "Requirement already satisfied: pytz in ./.venv/lib/python3.13/site-packages (from interchange~=2021.0.4->py2neo->neo4jupyter) (2025.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.13/site-packages (from jedi>=0.16->IPython>=4.0.0->neo4jupyter) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.1.0 in ./.venv/lib/python3.13/site-packages (from neo4jrestclient>=2.1.0->ipython-cypher>=0.2.4->neo4jupyter) (2.32.3)\n",
            "Requirement already satisfied: pillow in ./.venv/lib/python3.13/site-packages (from pansi>=2020.7.3->py2neo->neo4jupyter) (11.2.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.13/site-packages (from pexpect>4.3->IPython>=4.0.0->neo4jupyter) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython>=4.0.0->neo4jupyter) (0.2.13)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.13/site-packages (from stack_data->IPython>=4.0.0->neo4jupyter) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.13/site-packages (from stack_data->IPython>=4.0.0->neo4jupyter) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in ./.venv/lib/python3.13/site-packages (from stack_data->IPython>=4.0.0->neo4jupyter) (0.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.1.0->neo4jrestclient>=2.1.0->ipython-cypher>=0.2.4->neo4jupyter) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.1.0->neo4jrestclient>=2.1.0->ipython-cypher>=0.2.4->neo4jupyter) (3.10)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: neo4j in ./.venv/lib/python3.13/site-packages (5.28.1)\n",
            "Requirement already satisfied: pytz in ./.venv/lib/python3.13/site-packages (from neo4j) (2025.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: kagglehub in ./.venv/lib/python3.13/site-packages (0.3.12)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.13/site-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->kagglehub) (2025.4.26)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/javascript": "var link = document.createElement(\"link\");\n\tlink.rel = \"stylesheet\";\n\tlink.type = \"text/css\";\n\tlink.href = \"https://cdnjs.cloudflare.com/ajax/libs/vis/4.8.2/vis.css\";\n\tdocument.head.appendChild(link);\nrequire.config({     paths: {         vis: '//cdnjs.cloudflare.com/ajax/libs/vis/4.8.2/vis.min'     } }); require(['vis'], function(vis) {  window.vis = vis; }); ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "py2neo version 2021.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade py2neo\n",
        "!pip install ipykernel\n",
        "!pip install --upgrade neo4jupyter\n",
        "!pip install --upgrade neo4j\n",
        "!pip install pandas\n",
        "!pip install kagglehub\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "#permite conectarse a la BD\n",
        "#Fuente: https://py2neo.org/2021.1/\n",
        "import py2neo\n",
        "from py2neo import Graph,Node,Relationship\n",
        "\n",
        "#permite representar gráficamente los grafos obtenidos\n",
        "#Fuente: https://github.com/merqurio/neo4jupyter\n",
        "import neo4jupyter\n",
        "neo4jupyter.init_notebook_mode()\n",
        "\n",
        "\n",
        "print ('py2neo version', py2neo.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autenticación a la base ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "jCOJik7i7hNm",
        "outputId": "4529db16-b35f-4f9b-d7ea-8092bb119de4"
      },
      "outputs": [],
      "source": [
        "# url de la BD\n",
        "dburl='bolt://localhost:7687'\n",
        "\n",
        "#indica usuario y pass a la BD\n",
        "user=\"neo4j\"\n",
        "pasw=\"Sustiuir por la contraseña de la BD\"\n",
        "\n",
        "graph = Graph(dburl, auth=(user, pasw))\n",
        "\n",
        "from pandas import read_csv,isnull\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "uri             = dburl # url of your neo4j proyect, for example \"bolt://localhost:7687\"\n",
        "\n",
        "userName        = user # username\n",
        "\n",
        "password        = pasw # user password\n",
        "\n",
        "# Connect to the neo4j database server\n",
        "\n",
        "graphDB_Driver  = GraphDatabase.driver(uri, auth=(userName, password))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importación de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5jzfjki8AG4",
        "outputId": "5493ca65-7a15-4bec-bb24-85c01a749a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:02<00:00, 11.17it/s]\n"
          ]
        }
      ],
      "source": [
        "file_noc = 'files/teams.csv'\n",
        "\n",
        "# LOAD TEAMS + ARENA\n",
        "\n",
        "with graphDB_Driver.session() as graphDB_Session:\n",
        "    df = read_csv(file_noc,low_memory=False)\n",
        "    largo = len(df.index)\n",
        "    print(largo)\n",
        "    for idx in tqdm(range(0,largo)):\n",
        "        # get the information of each row\n",
        "        wanted_df_slice = df.iloc[[idx]]\n",
        "        team_id = str(wanted_df_slice.TEAM_ID.values[0])\n",
        "        name = str(wanted_df_slice.NICKNAME.values[0])\n",
        "        arena = str(wanted_df_slice.ARENA.values[0])\n",
        "        # cypher query to create the players nodes and their relationship \"PLAYED\" that matches each player with the games they played and their stats\n",
        "        cqlNodeQuery  = 'MERGE (t: Team {id: \\'' + team_id +'\\', name: \\'' + name +'\\' })'\n",
        "        cqlNodeQuery += 'MERGE (a: Arena {id: \\''+ arena +'\\'})'\n",
        "        cqlNodeQuery += 'MERGE (t)-[:HAS_ARENA]->(a)'\n",
        "\n",
        "        # Query the graph\n",
        "        nodes = graphDB_Session.run(cqlNodeQuery)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "44ASU7Zh8MKe"
      },
      "outputs": [],
      "source": [
        "file_noc = 'files/ranking.csv'\n",
        "\n",
        "# LOAD CONFERENCES and relationships\n",
        "\n",
        "with graphDB_Driver.session() as graphDB_Session:\n",
        "    df = read_csv(file_noc,low_memory=False)\n",
        "    largo = len(df.index)\n",
        "    teams=set()\n",
        "    for idx in range(0,largo):\n",
        "        # get the information of each row\n",
        "        wanted_df_slice = df.iloc[[idx]]\n",
        "        team_id = str(wanted_df_slice.TEAM_ID.values[0])\n",
        "        conference = str(wanted_df_slice.CONFERENCE.values[0])\n",
        "        # cypher query to create the players nodes and their relationship \"PLAYED\" that matches each player with the games they played and their stats\n",
        "        cqlNodeQuery = 'MATCH (t:Team {id: \\''+ team_id +'\\'}) '\n",
        "        cqlNodeQuery += 'MERGE (conf:Conference {id: \\''+ conference +'\\'})'\n",
        "        cqlNodeQuery += 'MERGE (t)-[:BELONGS]->(conf)'\n",
        "        if len(teams) < 30 :\n",
        "          if team_id not in teams: # do not add team to conference twice\n",
        "            nodes = graphDB_Session.run(cqlNodeQuery)\n",
        "            teams.add(team_id)\n",
        "        else:\n",
        "          break;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W76H5wRe8OGN",
        "outputId": "00fe8f19-8a4e-45f1-c112-38a85e8ad6e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26651/26651 [06:45<00:00, 65.66it/s]\n"
          ]
        }
      ],
      "source": [
        "file_noc = 'files/games.csv'\n",
        "\n",
        "with graphDB_Driver.session() as graphDB_Session:\n",
        "    df = read_csv(file_noc,low_memory=False)\n",
        "    largo = len(df.index) #\n",
        "    with graphDB_Session.begin_transaction() as tx:\n",
        "      for idx in tqdm(range(0,largo)):\n",
        "          # get the information of each row\n",
        "          wanted_df_slice = df.iloc[[idx]]\n",
        "\n",
        "          game_id = str(wanted_df_slice.GAME_ID.values[0])\n",
        "          home_team_wins = bool(wanted_df_slice.HOME_TEAM_WINS.values[0])\n",
        "          home_team = str(wanted_df_slice.HOME_TEAM_ID.values[0])\n",
        "          away_team = str(wanted_df_slice.VISITOR_TEAM_ID.values[0])\n",
        "          winner_team = home_team if home_team_wins else away_team\n",
        "          loser_team = away_team if home_team_wins else home_team\n",
        "          season = str(wanted_df_slice.SEASON.values[0])\n",
        "          date = str(wanted_df_slice.GAME_DATE_EST.values[0])\n",
        "          #home team data\n",
        "\n",
        "          home_pts = \"0\" if isnull(wanted_df_slice.PTS_home.values[0]) else str(wanted_df_slice.PTS_home.values[0])\n",
        "          home_fg_pct = \"0\" if isnull(wanted_df_slice.FG_PCT_home.values[0]) else str(wanted_df_slice.FG_PCT_home.values[0])\n",
        "          home_ft_pct = \"0\" if isnull(wanted_df_slice.FT_PCT_home.values[0]) else str(wanted_df_slice.FT_PCT_home.values[0])\n",
        "          home_fg3m_pct = \"0\" if isnull(wanted_df_slice.FG3_PCT_home.values[0]) else str(wanted_df_slice.FG3_PCT_home.values[0])\n",
        "          home_reb = \"0\" if isnull(wanted_df_slice.REB_home.values[0]) else str(wanted_df_slice.REB_home.values[0])\n",
        "          home_ast = \"0\" if isnull(wanted_df_slice.AST_home.values[0]) else str(wanted_df_slice.AST_home.values[0])\n",
        "\n",
        "          #away team data\n",
        "\n",
        "          away_pts = \"0\" if isnull(wanted_df_slice.PTS_away.values[0]) else str(wanted_df_slice.PTS_away.values[0])\n",
        "          away_fg_pct = \"0\" if isnull(wanted_df_slice.FG_PCT_away.values[0]) else str(wanted_df_slice.FG_PCT_away.values[0])\n",
        "          away_ft_pct = \"0\" if isnull(wanted_df_slice.FT_PCT_away.values[0]) else str(wanted_df_slice.FT_PCT_away.values[0])\n",
        "          away_fg3m_pct = \"0\" if isnull(wanted_df_slice.FG3_PCT_away.values[0]) else str(wanted_df_slice.FG3_PCT_away.values[0])\n",
        "          away_reb = \"0\" if isnull(wanted_df_slice.REB_away.values[0]) else str(wanted_df_slice.REB_away.values[0])\n",
        "          away_ast = \"0\" if isnull(wanted_df_slice.AST_away.values[0]) else str(wanted_df_slice.AST_away.values[0])\n",
        "\n",
        "        # cypher query to create the relationship \"HOME_TEAM\" that matches the local team stats of each game\n",
        "          full_query  = 'MATCH (ht:Team {id: \\''+ home_team +'\\'}) MATCH (at:Team {id: \\''+ away_team+'\\'})'\n",
        "          full_query  += ' MERGE (g: Game {id: \\'' + game_id +'\\', date: DATE(\\'' + date+'\\')}) MERGE (tsh: TeamSeason {id:\\''+home_team+season+'\\'}) MERGE (ht)-[:_'+season+']->(tsh)'\n",
        "          full_query  += ' MERGE (g)-[r:HOME_TEAM {PTS: '+ home_pts +', FG_PCT: '+ home_fg_pct +', FT_PCT: '+home_ft_pct+', AST: '+home_ast+', REB: '+home_reb+' }]->(tsh)'\n",
        "          full_query += ' MERGE (s:Season {id: \\'' + season +'\\'}) MERGE (tsh)-[:SEASON]->(s)'\n",
        "          # cypher query to create the relationship \"AWAY_TEAM\" that matches the away team stats of each game\n",
        "          full_query += ' MERGE (tsa: TeamSeason {id:\\''+away_team+season+'\\'}) MERGE (at)-[:_'+season+']->(tsa)'\n",
        "          full_query += ' MERGE (g)-[o:AWAY_TEAM {PTS: '+ away_pts +', FG_PCT: '+ away_fg_pct +', FT_PCT: '+away_ft_pct+', AST: '+away_ast+', REB: '+away_reb+' }]->(tsa)'\n",
        "          full_query += ' MERGE (tsa)-[:SEASON]->(s)'\n",
        "          # add winner and loser\n",
        "          full_query +=' MERGE (g)-[:WINNER]->(tsh) MERGE (g)-[:LOSER]->(tsa)' if home_team_wins else ' MERGE (g)-[:WINNER]->(tsa) MERGE (g)-[:LOSER]->(tsh)'\n",
        "\n",
        "\n",
        "          # Season query\n",
        "          tx.run(full_query)\n",
        "          if idx % 100 == 0:\n",
        "             tx.commit()\n",
        "             tx = graphDB_Session.begin_transaction()\n",
        "\n",
        "      tx.commit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOhQqjnm8SVl",
        "outputId": "ff9513d9-6358-4914-adc8-763138fb9346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "668628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400127/400127 [1:24:07<00:00, 79.28it/s]  \n"
          ]
        }
      ],
      "source": [
        "file_noc = 'files/games_details.csv'\n",
        "time_dict = {}\n",
        "with graphDB_Driver.session() as graphDB_Session:\n",
        "    df = read_csv(file_noc,low_memory=False)\n",
        "    largo = len(df.index)\n",
        "    print(largo)\n",
        "\n",
        "    with graphDB_Session.begin_transaction() as tx:\n",
        "      # 68501\n",
        "      for idx in tqdm(range(268501,largo)): # Re-run from new range if fails\n",
        "          # get the information of each row\n",
        "          wanted_df_slice = df.iloc[[idx]]\n",
        "          game_id = str(wanted_df_slice.GAME_ID.values[0])\n",
        "          name = '\\\"'+str(wanted_df_slice.PLAYER_NAME.values[0])+'\\\"'\n",
        "          player_id = str(wanted_df_slice.PLAYER_ID.values[0])\n",
        "          team_id = str(wanted_df_slice.TEAM_ID.values[0])\n",
        "          time_played = str(wanted_df_slice.MIN.values[0])\n",
        "          secs = 0 # defalut value that represents \"Do not play\"\n",
        "          # if Min column has some value, we need to calculate the seconds and store it\n",
        "          if not isnull(wanted_df_slice.MIN.values[0]) :\n",
        "              # we split in minutes and seconds\n",
        "              mins_slice = time_played.split(\":\")\n",
        "              # if play at least 1 minute, we need to calculate that time in seconds\n",
        "              if len(mins_slice) > 1 : # there is wrong data of \"-5\" seconds played by some players\n",
        "                  secs = int(float(mins_slice[0]))*60+int(float(mins_slice[1]))\n",
        "\n",
        "          fgm = \"0\" if isnull(wanted_df_slice.FGM.values[0]) else str(wanted_df_slice.FGM.values[0])\n",
        "          fga = \"0\" if isnull(wanted_df_slice.FGA.values[0]) else str(wanted_df_slice.FGA.values[0])\n",
        "          fg3a = \"0\" if isnull(wanted_df_slice.FG3A.values[0]) else str(wanted_df_slice.FG3A.values[0])\n",
        "          fg3m = \"0\" if isnull(wanted_df_slice.FG3M.values[0]) else str(wanted_df_slice.FG3M.values[0])\n",
        "          ftm = \"0\" if isnull(wanted_df_slice.FTM.values[0]) else str(wanted_df_slice.FTM.values[0])\n",
        "          fta = \"0\" if isnull(wanted_df_slice.FTA.values[0]) else str(wanted_df_slice.FTA.values[0])\n",
        "          oreb = \"0\" if isnull(wanted_df_slice.OREB.values[0]) else str(wanted_df_slice.OREB.values[0])\n",
        "          dreb = \"0\" if isnull(wanted_df_slice.DREB.values[0]) else str(wanted_df_slice.DREB.values[0])\n",
        "          reb = \"0\" if isnull(wanted_df_slice.REB.values[0]) else str(wanted_df_slice.REB.values[0])\n",
        "          ast = \"0\" if isnull(wanted_df_slice.AST.values[0]) else str(wanted_df_slice.AST.values[0])\n",
        "          stl = \"0\" if isnull(wanted_df_slice.STL.values[0]) else str(wanted_df_slice.STL.values[0])\n",
        "          blk = \"0\" if isnull(wanted_df_slice.BLK.values[0]) else str(wanted_df_slice.BLK.values[0])\n",
        "          to = \"0\" if isnull(wanted_df_slice.TO.values[0]) else str(wanted_df_slice.TO.values[0])\n",
        "          pf = \"0\" if isnull(wanted_df_slice.PF.values[0]) else str(wanted_df_slice.PF.values[0])\n",
        "          pts = \"0\" if isnull(wanted_df_slice.PTS.values[0]) else str(wanted_df_slice.PTS.values[0])\n",
        "          # cypher query to create the players nodes and their relationship \"PLAYED\" that matches each player with the games they played and their stats\n",
        "          cqlNodeQuery  = 'MATCH (g: Game {id: \\'' + game_id +'\\' })'\n",
        "          cqlNodeQuery += 'MERGE (p: Player {id: \\''+ player_id +'\\', name: '+ name +'})'\n",
        "\n",
        "          cqlNodeQuery += 'MERGE (p)-[r:PLAYED {team: \\''+ team_id +'\\', time_played:'+ str(secs) +', FGM: '+fgm+', FGA: '+fga+', FG3A: '+fg3a+',FG3M: '+fg3m+',FTM: '+ftm+', FTA: '+fta+', OREB: '+oreb+',DREB: '+dreb+', REB: '+reb+', AST: '+ast+',STL: '+stl+', BLK: '+blk+', FOULS: '+to+', PF: '+pf+', PTS: '+pts+' }]->(g)'\n",
        "          cqlNodeQuery +=' SET g.time_played = COALESCE(g.time_played, 0) +'+str(secs/10)\n",
        "\n",
        "\n",
        "          # Query the graph\n",
        "          tx.run(cqlNodeQuery)\n",
        "          if idx % 100 == 0:\n",
        "             tx.commit()\n",
        "             last_loaded_row = idx\n",
        "             tx = graphDB_Session.begin_transaction()\n",
        "\n",
        "      tx.commit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creación de aristas para el subgrafo de distancias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IuYPHb9YKmm"
      },
      "outputs": [],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "  session.run(\"\"\"\n",
        "    MATCH (p1:Player)-[pl1:PLAYED]->(g:Game)<-[pl2:PLAYED]-(p2:Player)\n",
        "    WHERE elementId(p1) < elementId(p2)\n",
        "    WITH p1, p2, count(g) AS shared_games\n",
        "    MERGE (p1)-[r:SHARED_GAME_WITH]->(p2)\n",
        "    SET r.weight = 1.0/shared_games, r.shared_games = shared_games\n",
        "  \"\"\")\n",
        "\n",
        "\n",
        "  session.run(\"\"\"\n",
        "  MATCH (p1:Player)-[pl1:PLAYED]->(g:Game)<-[pl2:PLAYED]-(p2:Player)\n",
        "  WHERE elementId(p1) < elementId(p2) AND pl1.team = pl2.team\n",
        "  WITH p1, p2, count(g) AS shared_games_as_ally\n",
        "  MERGE (p1)-[r:ALLY]->(p2)\n",
        "  SET r.weight = 1.0/shared_games_as_ally, r.shared_games_as_ally = shared_games_as_ally\n",
        "  \"\"\")\n",
        "\n",
        "  session.run(\"\"\"\n",
        "    MATCH (p1:Player)-[pl1:PLAYED]->(g:Game)<-[pl2:PLAYED]-(p2:Player)\n",
        "    WHERE elementId(p1) < elementId(p2) AND pl1.team <> pl2.team\n",
        "    WITH p1, p2, count(g) AS shared_games_as_rival\n",
        "    MERGE (p1)-[r:RIVAL]->(p2)\n",
        "    SET r.weight = 1.0/shared_games_as_rival, r.shared_games_as_rival = shared_games_as_rival\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejemplo de consulta para distancia de jugadores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uLV50LOC-iL",
        "outputId": "e16aada0-ea70-46eb-f110-4517dc296aa7"
      },
      "outputs": [],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    session.run(\"\"\"\n",
        "        MATCH p = SHORTEST 1 (p1:Player {name:\"LeBron James\"})-[:SHARED_GAME_WITH]-+(p2:Player {name: \"Kyrie Irving\"})\n",
        "        RETURN p\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distancia General"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creación del grafo proyectado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    session.run(\"\"\"\n",
        "        CALL gds.graph.project(\n",
        "        'distanceGraph',\n",
        "        'Player',\n",
        "        {\n",
        "                        SHARED_GAME_WITH: {\n",
        "                                    orientation: 'UNDIRECTED',\n",
        "                                    properties: 'weight'\n",
        "                                }\n",
        "                    }\n",
        "        )\n",
        "        YIELD graphName, nodeCount, relationshipCount;\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Betweenness Centrality:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LeBron James: 74949.8788\n",
            "Jamal Crawford: 72305.6500\n",
            "Kyle Korver: 66967.0833\n",
            "Jeff Teague: 62555.3278\n",
            "LaMarcus Aldridge: 61787.7634\n",
            "Dirk Nowitzki: 61424.1357\n",
            "Udonis Haslem: 60960.3268\n",
            "James Harden: 58319.2837\n",
            "Marvin Williams: 57050.1326\n",
            "JJ Redick: 56404.3742\n"
          ]
        }
      ],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        CALL gds.betweenness.stream('distanceGraph', { relationshipWeightProperty: 'weight' })\n",
        "        YIELD nodeId, score\n",
        "        RETURN gds.util.asNode(nodeId).name AS name, score\n",
        "        ORDER BY score DESC\n",
        "        LIMIT 10;\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        print(f\"{record['name']}: {record['score']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Degree Centrality:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Udonis Haslem: 487.7100\n",
            "Kyle Korver: 483.9077\n",
            "Tyson Chandler: 474.4265\n",
            "Dwight Howard: 469.1686\n",
            "Dwyane Wade: 458.8847\n",
            "Pau Gasol: 457.9605\n",
            "Vince Carter: 454.6061\n",
            "Trevor Ariza: 442.5471\n",
            "Dirk Nowitzki: 439.6372\n",
            "Joe Johnson: 432.1212\n"
          ]
        }
      ],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        CALL gds.degree.stream('distanceGraph', { relationshipWeightProperty: 'weight' })\n",
        "        YIELD nodeId, score\n",
        "        RETURN gds.util.asNode(nodeId).name AS name, score\n",
        "        ORDER BY score DESC\n",
        "        LIMIT 10;\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        print(f\"{record['name']}: {record['score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Closeness Centrality:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Udonis Haslem: 0.7768\n",
            "Kyle Korver: 0.7751\n",
            "Vince Carter: 0.7736\n",
            "LeBron James: 0.7603\n",
            "Tyson Chandler: 0.7595\n",
            "Pau Gasol: 0.7590\n",
            "Dwyane Wade: 0.7562\n",
            "Zaza Pachulia: 0.7541\n",
            "Nene: 0.7541\n",
            "Dirk Nowitzki: 0.7536\n"
          ]
        }
      ],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        CALL gds.closeness.stream('distanceGraph')\n",
        "        YIELD nodeId, score\n",
        "        RETURN gds.util.asNode(nodeId).name AS name, score\n",
        "        ORDER BY score DESC\n",
        "        LIMIT 10;\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        print(f\"{record['name']}: {record['score']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detección de comunidades: Louvain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Community Count: 3, Modularity: 0.3116\n"
          ]
        }
      ],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        CALL gds.louvain.stats('distanceGraph', {relationshipWeightProperty: 'weight'})\n",
        "        YIELD communityCount, modularity\n",
        "        RETURN communityCount, modularity;\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        print(f\"Community Count: {record['communityCount']}, Modularity: {record['modularity']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detección de comunidades: Leiden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Community Count: 3, Modularity: 0.3116\n"
          ]
        }
      ],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        CALL gds.leiden.stats('distanceGraph', {relationshipWeightProperty: 'weight'})\n",
        "        YIELD communityCount, modularity\n",
        "        RETURN communityCount, modularity;\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        print(f\"Community Count: {record['communityCount']}, Modularity: {record['modularity']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DISTANCIA ALIADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creación del grafo proyectado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    session.run(\"\"\"\n",
        "        CALL gds.graph.project(\n",
        "        'allyGraph',\n",
        "        'Player',\n",
        "        {\n",
        "                        ALLY: {\n",
        "                                    orientation: 'UNDIRECTED',\n",
        "                                    properties: 'weight'\n",
        "                                }\n",
        "                    }\n",
        "        )\n",
        "        YIELD graphName, nodeCount, relationshipCount;\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detección de comunidades: Louvain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Community Count: 19, Modularity: 0.4319\n"
          ]
        }
      ],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        CALL gds.louvain.stats('allyGraph',{ relationshipWeightProperty: 'weight' })\n",
        "        YIELD communityCount, modularity\n",
        "        RETURN communityCount, modularity;\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        print(f\"Community Count: {record['communityCount']}, Modularity: {record['modularity']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detección de comunidades: Leiden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Community Count: 20, Modularity: 0.4306\n"
          ]
        }
      ],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        CALL gds.leiden.stats('allyGraph', { relationshipWeightProperty: 'weight' })\n",
        "        YIELD communityCount, modularity\n",
        "        RETURN communityCount, modularity;\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        print(f\"Community Count: {record['communityCount']}, Modularity: {record['modularity']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distancia Rival"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creación del grafo proyectado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    session.run(\"\"\"\n",
        "        CALL gds.graph.project(\n",
        "        'rivalGraph',\n",
        "        'Player',\n",
        "        {\n",
        "                    RIVAL: {\n",
        "                        orientation: 'UNDIRECTED',\n",
        "                        properties: 'weight'\n",
        "                    }\n",
        "                    }\n",
        "        )\n",
        "        YIELD graphName, nodeCount, relationshipCount;\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detección de comunidades: Louvain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Community Count: 3, Modularity: 0.3088\n"
          ]
        }
      ],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        CALL gds.louvain.stats('rivalGraph',{ relationshipWeightProperty: 'weight' })\n",
        "        YIELD communityCount, modularity\n",
        "        RETURN communityCount, modularity;\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        print(f\"Community Count: {record['communityCount']}, Modularity: {record['modularity']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Detección de comunidades: Leiden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Community Count: 3, Modularity: 0.3088\n"
          ]
        }
      ],
      "source": [
        "with graphDB_Driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        CALL gds.leiden.stats('rivalGraph', { relationshipWeightProperty: 'weight' })\n",
        "        YIELD communityCount, modularity\n",
        "        RETURN communityCount, modularity;\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        print(f\"Community Count: {record['communityCount']}, Modularity: {record['modularity']:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
